{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch 基础知识总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NOTATION:\n",
    "    axis = 1 # for rwo op\n",
    "    axis = 0 # for col op\n",
    "\n",
    "\n",
    "##two methods define the type of tensor\n",
    "tensor.type(torch.float32)\n",
    "torch.ones_like(tensor, dtype=torch.float32)\n",
    "\n",
    "##numpy 更改数据类型\n",
    "nparray.astype(np.int32)\n",
    "\n",
    "##numpy.ndarray to Tensor\n",
    "torch.Tensor(numpy_array)\n",
    "\n",
    "#numpy用array_np.shape来获取维度；tensor用tensor_ob.Size()来获取维度\n",
    "#pytorch调换维度\n",
    "tensor_ob.permute(2,1,3,4) #swap the demiention from (1, 2, 3, 4) to (2, 1, 3, 4)\n",
    "\n",
    "#增加维度, 也可用torch.stack()来实现\n",
    "tensor_ob[None,:,:,:] #from (:,:,:) to (1,:,:,:)\n",
    "\n",
    "#从python数组构建tensor\n",
    "torch.Tensor([[1,...,2],[1,...,2]])\n",
    "\n",
    "#将tensor向量转换为矩阵\n",
    "torch.unsqueeze(tensor_ob, 0) #parameter 0 to 1 row tensor, 1 to 1 col tensor\n",
    "eg: \n",
    "    va = torch.tensor(2, 3)\n",
    "    va = va.unsqueeze(1)  #shape [2, 3] to [2, 1, 3]; 1表示在那个维度解压缩\n",
    "    va_ = va.unsqueeze(0) #shape[2, 3] to [1, 2, 3]; paramer range [-2, 1]\n",
    "\n",
    "#view来改变tensor矩阵维度\n",
    "tensor_ob.view(row_num,col_num)\n",
    "\n",
    "#tensor 和 numpy的转换\n",
    "a = np.randn(3, 5)\n",
    "a2tensor = torch.from_numpy(a)\n",
    "\n",
    "#** stack可将n个size为(3， 224， 224)堆叠在一起形成(n, 3, 224, 224)高维矩阵\n",
    "n_stack = []\n",
    "for idx in range(n):\n",
    "    elem = torch.randn(3, 224, 224)\n",
    "    n_stack.append(elem)\n",
    "x = torch.stack(n_stack) #x.Size() (n, 3, 224, 224)\n",
    "\n",
    "#repeat操作来复制维度\n",
    ">>> x = torch.tensor([1, 2, 3])\n",
    ">>> x.repeat(4, 2)\n",
    "tensor([[ 1,  2,  3,  1,  2,  3],\n",
    "        [ 1,  2,  3,  1,  2,  3],\n",
    "        [ 1,  2,  3,  1,  2,  3],\n",
    "        [ 1,  2,  3,  1,  2,  3]])\n",
    ">>> x.repeat(4, 2, 1).size()\n",
    "torch.Size([4, 2, 3])\n",
    "\n",
    "#ne 操作来判断tensor 值是否相同，不同是1，相同返回0，是逐元素的\n",
    ">>> torch.ne(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\n",
    "tensor([[ 0,  1],\n",
    "        [ 1,  0]], dtype=torch.uint8)\n",
    "\n",
    "#cat 操作来讲tensor连结在一起；paramer 的尺寸应该相同，channels可以不同\n",
    ">>> x = torch.randn(2, 3)\n",
    ">>> x\n",
    "tensor([[ 0.6580, -1.0969, -0.4614],\n",
    "        [-0.1034, -0.5790,  0.1497]])\n",
    ">>> torch.cat((x, x, x), 0)  #for row\n",
    "tensor([[ 0.6580, -1.0969, -0.4614],\n",
    "        [-0.1034, -0.5790,  0.1497],\n",
    "        [ 0.6580, -1.0969, -0.4614],\n",
    "        [-0.1034, -0.5790,  0.1497],\n",
    "        [ 0.6580, -1.0969, -0.4614],\n",
    "        [-0.1034, -0.5790,  0.1497]])\n",
    ">>> torch.cat((x, x, x), 1) #for col\n",
    "tensor([[ 0.6580, -1.0969, -0.4614,  0.6580, -1.0969, -0.4614,  0.6580,\n",
    "         -1.0969, -0.4614],\n",
    "        [-0.1034, -0.5790,  0.1497, -0.1034, -0.5790,  0.1497, -0.1034,\n",
    "         -0.5790,  0.1497]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL basic op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##convolution op\n",
    "torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "#用法实例\n",
    "self.conv_1 = nn.Sequential(\n",
    "                            nn.Conv2d(512, 256, 3, 1, 1)), #input channels: 512, output channels: 256, kernel_size:3, stride and padding both are 1\n",
    "                            nn.BatchNorm2d(256),\n",
    "                            nn.ReLU()\n",
    "        )\n",
    "x = self.conv_1(troch.randn(3, 512, 224, 224))  #x.Size() to (3, 256, 224, 224)\n",
    "**note:** 当dilation>1时，普通卷积称为空洞卷积(atrous convolution)\n",
    "    \n",
    "##FC layer\n",
    "torch.nn.Linear(in_features, out_features, bias=True)\n",
    "Input: (N,∗,in_features) #where *∗ means any number of additional dimensions\n",
    "Output: (N,∗,out_features) #where all but last dim are out_features\n",
    "eg:\n",
    ">>> m = nn.Linear(20, 30)\n",
    ">>> input = torch.randn(128, 20)\n",
    ">>> output = m(input)\n",
    ">>> print(output.size())\n",
    "torch.Size([128, 30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
