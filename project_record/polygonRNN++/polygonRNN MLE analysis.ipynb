{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## poly_vertex_loss\n",
    "def poly_vertex_loss(targets, mask, logits):\n",
    "    '''\n",
    "    targets: 网络预测的vertex shape:[b_s, time_steps, grid_size**2+1]\n",
    "    '''\n",
    "    \"\"\"\n",
    "    Classification loss for polygon vertex prediction\n",
    "\n",
    "    targets: [batch_size, time_steps, grid_size**2+1],\n",
    "    Each element is y*grid_size + x, or grid_size**2 for EOS\n",
    "    mask: [batch_size, time_steps], mask of GT\n",
    "    Mask stipulates whether this time step is used for training\n",
    "    logits: [batch_size, time_steps, grid_size**2 + 1]\n",
    "    \"\"\"\n",
    "    batch_size = mask.size(0)\n",
    "    \n",
    "    # Remove the zeroth time step\n",
    "    # view used for contiguous memory, '.contiguous()' for this purpose\n",
    "    logits = logits[:, 1:, :].contiguous().view(-1, logits.size(-1)) # (batch*(time_steps-1), grid_size**2 + 1)\n",
    "    targets = targets[:, 1:, :].contiguous().view(-1, logits.size(-1)) # (batch*(time_steps-1), grid_size**2 + 1)\n",
    "    mask = mask[:, 1:].contiguous().view(-1) # (batch*(time_steps-1))\n",
    "\n",
    "    # Cross entropy between targets and softmax outputs\n",
    "    loss = torch.sum(-targets * F.log_softmax(logits, dim=1), dim=1)\n",
    "    loss = loss * mask.type_as(loss)\n",
    "    loss = loss.view(batch_size, -1)\n",
    "    # Sum across time\n",
    "    loss = torch.sum(loss, dim=1)\n",
    "    # Mean across batches\n",
    "    return torch.mean(loss)\n",
    "\n",
    "## fp_edge_loss\n",
    "def fp_edge_loss(gt_edges, edge_logits):\n",
    "    \"\"\"\n",
    "    Edge loss in the first point network\n",
    "\n",
    "    gt_edges: [batch_size, grid_size, grid_size] of 0/1\n",
    "    edge_logits: [batch_size, grid_size*grid_size]\n",
    "    \"\"\"\n",
    "    edges_shape = gt_edges.size()\n",
    "    gt_edges = gt_edges.view(edges_shape[0], -1)\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(edge_logits, gt_edges)\n",
    "\n",
    "    return torch.mean(loss)\n",
    "    \n",
    "    \n",
    "## fp_vertex_loss\n",
    "def fp_vertex_loss(gt_verts, vertex_logits):\n",
    "    \"\"\"\n",
    "    Vertex loss in the first point network\n",
    "    \n",
    "    gt_verts: [batch_size, grid_size, grid_size] of 0/1\n",
    "    vertex_logits: [batch_size, grid_size**2]\n",
    "    \"\"\"\n",
    "    verts_shape = gt_verts.size()\n",
    "    gt_verts = gt_verts.view(verts_shape[0], -1)\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(vertex_logits, gt_verts) # 2 classifacation loss\n",
    "\n",
    "    return torch.mean(loss)\n",
    "\n",
    "\n",
    "\n",
    "...\n",
    "loss = losses.poly_vertex_loss_mle(torch.from_numpy(dt_targets).cuda(),data['mask'].cuda(), output['logits']) # data['mask']=1\n",
    "fp_edge_loss = self.opts['fp_weight'] * losses.fp_edge_loss(data['edge_mask'].cuda(),output['edge_logits'])\n",
    "fp_vertex_loss = self.opts['fp_weight'] * losses.fp_vertex_loss(data['vertex_mask'].cuda(),output['vertex_logits'])\n",
    "\n",
    "total_loss = loss+fp_edge_loss+fp_vertex_loss\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
