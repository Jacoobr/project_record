{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handle parameter use argparser object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "def get_args():\n",
    "    parser =argparse.ArgumentParser() #get ArgumentParser object\n",
    "    parser.add_argument('--exp', type=str)\n",
    "    parser.add_argument('--lr', type=int)\n",
    "    ...\n",
    "    args = parser.parser_args()# handle the parser as an object with argument attribute\n",
    "    return args\n",
    "\n",
    "#use the args object, FEP, --exp parameter point to a json config file\n",
    "...\n",
    "opts = json.load(open(args.exp, 'r')) # get the --exp argument value by '.' op like args.exp\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## pytorch加载模型的两种方式\n",
    "# way 1\n",
    "saved_stated_dict = torch.load('model_path')\n",
    "model_dict = model.state_dict() #get the model_dic object\n",
    "model_dict = model_dict.update(saved_stated_dict) #update the net model parameter dict\n",
    "model.load_state_dict(model_dict) #load the updated state dict\n",
    "# way 2\n",
    "saved_state_dict = torch.load(args['--snapshots'])\n",
    "model.load_state_dict(saved_state_dict)\n",
    "## load all parameter to CPU or GPU\n",
    "torch.load('model_path', map_location=lambda:storage, loc: storage) # 到cpu\n",
    "torch.load('model_path', map_location=lambda:storage, loc: storage.cuda(1)) #onto GPU 1\n",
    "torch.load('model_path', map_location={'cuda:1':'cuda:0'}) #from GPU 1 to GPU 2\n",
    "## another way to load model\n",
    "with open('model_.pth') as f:\n",
    "    buffer = io.BytesIO(f.read()) #convert readed stream to Bytes buffer\n",
    "torch.load(buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(params):\n",
    "    save_sate={\n",
    "        'epoch':epoch,\n",
    "        'global_step':self.global_step,\n",
    "        'state_dict':self.model.state_dict(),\n",
    "        'optimizer':self.optimizer.state_dict(), #state_dict for optimizer\n",
    "        'lr_decay':self.lr_decay.state_dict() #state_dict for lr_decay \n",
    "    }\n",
    "    save_name = os.path.join(self.opts['exp_dir'], 'checkpoints', 'epoch%d_step%d.pth'%(epoch, self.global_step))\n",
    "    torch.save(save_state, save_name) #save model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch 的数据准备和预处理(to pytorch data format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础知识\n",
    "DataProvider.py  作用是将一张张图像和GT处理成torch能够处理的 [original_image.tensor, gt.tensor], 然后只需在train.py中导入即可.\n",
    "1. torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sample=None, batch_sampler=None, num_workers=0, collate_fn=<function default_collate>, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None)\n",
    "注意4个参数:\n",
    "    batch_size:批处理数目; shuffle:是否每个epoch都打乱； num_workers: 采用几线程来load数据; collate_fn: 将sample到的数据组织成mini-batch（ merges a list of samples to form a mini-batch） #reference: https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader \n",
    "    \n",
    "2. 需要的库：\n",
    "    import torch.utils.data #子类化自己的数据dataset\n",
    "    import torch \n",
    "    from torchvision import transform #对数据做预处理，比如旋转，高斯模糊等Data Augmentation\n",
    "    \n",
    "3.子类化(class: 属性+方法 )自己的数据：\n",
    "    class DataProvider(torch.utils.data.DataLoader):\n",
    "   \n",
    "4.添加必要的override函数\n",
    "    def __init__(self): #初始化定义的属性\n",
    "    \n",
    "    def __len__(self): #提供数据集大小\n",
    "    \n",
    "    def __getitem__(self): # 提供下标index索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataProvider template 模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "class DataProvider(torch.utils.data.Dataset): #子类化\n",
    "    def __init__(self, img_root, transform=None, train=True):\n",
    "        self.img_root=img_root\n",
    "        self.train=train\n",
    "    \n",
    "    def __getitem__(self, idx): #装在图片数据， 返回[image, GT], idx：索引一张一张的图片\n",
    "        img=imread(img_path) #读取数据\n",
    "        img=torch.from_numpy(img).float() #将ndarray convert to tensor, must be float\n",
    "        ...\n",
    "        return img, gt\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imagenumber) #返回加载的数据长度\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  具体例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data # for subclass of DataSet\n",
    "from scipy.ndimage import imread # to read RGB image; from scipy import misc, or misc.imread() / misc.imsave()\n",
    "import torch\n",
    "import os\n",
    "import glob # for search the files in directory\n",
    "from torchvision import transforms # for data augmentation op\n",
    "\n",
    "## 读取自己的数据集，返回[original_img_path, GT_img_path] pair for training\n",
    "## if one need transform before return image, gt pair\n",
    "## just add '''img = transforms.ToTensor() gt = transforms.ToTensor()''' code before return.\n",
    "def handle_dataset_train(root_path, train=True):\n",
    "    dataset = []\n",
    "    if train:\n",
    "        img_path=os.path.join(root_path, 'train/image/')\n",
    "        gt_path=os.path.join(root_path, 'train/gt/')\n",
    "        \n",
    "        for imgGT in glob.glob(os.path.join(gt_path, '*.jpg')): #regular expression search\n",
    "            image_name = os.path.basename(imgGT) #get the image name\n",
    "            \n",
    "            dataset.append([os.path.join(img_path, image_name), os.path.join(gt_path, image_name)]) #add the absolute image or GT image path\n",
    "    return dataset\n",
    "\n",
    "class DataProvider(data.DataSet): #subclassing\n",
    "    ## initialize attribute func\n",
    "    def __init__(self, img_root, transform=None, Train=True): #for getting each img_gt pair for train dataset. \n",
    "        self.img_root = img_root\n",
    "        self.transfor=transform\n",
    "        self.train=train\n",
    "        if self.train:\n",
    "            self.train_set_pair = handle_dataset_train(img_root, train):\n",
    "                \n",
    "    ## getitem func for indexing\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, gt_path = self.train_set_pair[idx]\n",
    "        \n",
    "        #for image\n",
    "        image = imread(img_path)# from scipy import misc; misc.imread()\n",
    "        image = np.atleast_3d(image).transpose(2,0,1).astype(npg.float32)\n",
    "        image = (image-image.min())/(image.max()-image.min()) # normalize op\n",
    "        image = torch.from_numpy(image).float32 #convert to torch tensor\n",
    "        \n",
    "        #for gt\n",
    "        gt = imread(img_path) \n",
    "        gt = atleast_3d(gt).transpose(2, 0, 1).astype(np.float32)\n",
    "        gt = gt/255.0 # for gray GT image normalize op\n",
    "        gt = torch.from_numpy(gt).float32 \n",
    "        \n",
    "        return image, gt\n",
    "    \n",
    "    ## return length func\n",
    "    def __len__(self):\n",
    "        return len(self.train_set_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch 的并行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    import multiprocessing.dummy as multiprocessing  ##python 线程池\n",
    "    ## 数据的多进程处理\n",
    "    def read_dataset(self):\n",
    "        data_list = glob.glob(osp.join(self.data_dir, '*/*.json'))\n",
    "        data_list = [[d, self.opts] for d in data_list]\n",
    "        pool = multiprocessing.Pool(self.opts['num_workers'])  #设置进程数量\n",
    "        data = pool.map(process_info, data_list) #Ordered results using pool.map(); process_info 为函数名，data_list为数据\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
